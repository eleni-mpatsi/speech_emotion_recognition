# speech_emotion_recognition
This project uses specific features (mean_centroid, std_centroid, mean_mfccs,std_mfccs, mean_bandwidth, std_bandwidth and emotion) from labeled data and Logistic Regression to recognise whether the speaker is calm or angry in real time (during talking to the microphone). 
